{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Copy of Copy of Copy of sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFUcnW3l3Tv2"
      },
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "required = {'numpy', 'pandas', 'tensorflow', 'keras'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHscwJLq5Uej"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Hl9in47S9-"
      },
      "source": [
        "### Import images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg_-ywsk7o7n"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "if not os.path.exists('keras_classification_sample'):\n",
        "  !git clone https://github.com/pazamelin/keras_classification_sample.git\n",
        "\n",
        "IMG_DIR = f'./keras_classification_sample/concrete-cracks/'\n",
        "CONFIG = {\n",
        "    'image_size': (227, 227),\n",
        "    'batch_size': 25,\n",
        "    'validation_split': 0.2,\n",
        "    'seed': random.randint(0, 99999) \n",
        "}\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(IMG_DIR, **CONFIG, subset=\"training\")\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(IMG_DIR, **CONFIG, subset=\"validation\")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(f'Class_names: {class_names}')\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TziH2mZ4FBnY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(10):\n",
        "    ax = plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKPSft16UqMD"
      },
      "source": [
        "## Custom CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVpEH5qcLJzE"
      },
      "source": [
        "### Instantiate a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmd2n3VfKseo"
      },
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(227, 227, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpX8oproKvgD"
      },
      "source": [
        "### Configure the model for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0rez-FiLCXd"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=['acc']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSawMvRtOyOR"
      },
      "source": [
        "### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfeE2qF6OxOr"
      },
      "source": [
        "import time\n",
        "\n",
        "# timing callback\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "        \n",
        "time_callback = TimeHistory()\n",
        "\n",
        "# fit model\n",
        "history = model.fit(train_ds,\n",
        "                    steps_per_epoch=32,\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_ds,\n",
        "                    validation_steps=50,\n",
        "                    callbacks=[time_callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCJQsw_7dBCr"
      },
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2,\n",
        "                    subplot_titles = ['Training and Validation Accuracy',\n",
        "                                      'Training and Validation Loss'])\n",
        "\n",
        "plots_positions = [(1, 1)] * 2 + [(1, 2)] * 2\n",
        "metric_names = ['acc', 'val_acc', 'loss', 'val_loss']\n",
        "epochs = list(range(1, history.params['epochs'] + 1))\n",
        "\n",
        "for metric, (plot_row, plot_col) in zip(metric_names, plots_positions):\n",
        "  fig.add_trace(\n",
        "    go.Scatter(name=metric,\n",
        "               x=epochs,\n",
        "               y=history.history[metric]),\n",
        "  row=plot_row, \n",
        "  col=plot_col\n",
        ")   \n",
        "\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhZLGMzjPtOR"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCkWIjtfPuqf"
      },
      "source": [
        "FV_IMG_DIR = f'./keras_classification_sample/final-validation'\n",
        "\n",
        "evaluate_ds = tf.keras.utils.image_dataset_from_directory(FV_IMG_DIR, image_size=(227,227), batch_size=25)\n",
        "print(\"Evaluate on test data\")\n",
        "custom_cnn_fv = model.evaluate(evaluate_ds, batch_size=25)\n",
        "print(\"test loss, test acc:\", custom_cnn_fv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiL0mccnJSiD"
      },
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import os, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "columns = 4\n",
        "fig = make_subplots(rows=1, cols=columns)\n",
        "\n",
        "img_names = []\n",
        "for i in range(0, int(columns / 2)):\n",
        "  img_names.append(f'{FV_IMG_DIR}/positive/' + random.choice(os.listdir(f'{FV_IMG_DIR}/positive/')))\n",
        "  img_names.append(f'{FV_IMG_DIR}/negative/' + random.choice(os.listdir(f'{FV_IMG_DIR}/negative/')))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "for i, img_name in enumerate(img_names):\n",
        "  ax = plt.subplot(1, columns, i + 1)\n",
        "  img = tf.keras.preprocessing.image.load_img(img_name, target_size=(227, 227))\n",
        "  img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  plt.imshow(img_array/255.)\n",
        "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "  score = model.predict(img_array)[0]\n",
        "  plt.title(f'negative: {1 - score}, positive: {score}')\n",
        "  plt.axis(\"off\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vp2_PpgQwsZ"
      },
      "source": [
        "## Framework Network: TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRnMZ4YpuQzM"
      },
      "source": [
        "## Training Times Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGk-FgI6nic9"
      },
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2,\n",
        "                    subplot_titles = ['training time per epoch',\n",
        "                                      'total time per epoch'])\n",
        "timing_data = [time_callback.times]\n",
        "timing_names = ['custom CNN']\n",
        "epochs = list(range(1, history.params['epochs'] + 1))\n",
        "\n",
        "for data, name in zip(timing_data, timing_names):\n",
        "  # plot time per epoch\n",
        "  fig.add_trace(\n",
        "    go.Scatter(name=name,\n",
        "               x=epochs,\n",
        "               y=data),\n",
        "    row = 1, col = 1   \n",
        "  )    \n",
        "\n",
        "# plot total time\n",
        "total_times = [sum(data) for data in timing_data]\n",
        "fig.add_trace(\n",
        "  go.Bar(name='total time',\n",
        "         x=timing_names,\n",
        "         y=total_times),\n",
        "    row = 1, col = 2   \n",
        "  )\n",
        "fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2eftZNDQlGt"
      },
      "source": [
        "## Final validation comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqrAfXpeQsfP"
      },
      "source": [
        "print(\"test loss, test acc:\", custom_cnn_fv)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}